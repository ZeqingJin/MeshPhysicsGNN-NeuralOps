{"cells":[{"cell_type":"markdown","source":["### This notebook pre-processes the .csv files obtained from simulation to .pt dataset file."],"metadata":{"id":"nn-RhDgzwncm"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15944,"status":"ok","timestamp":1691818096128,"user":{"displayName":"Zeqing Jin","userId":"08270832473685072946"},"user_tz":420},"id":"9eqiQRT054CY","outputId":"f74ac594-9946-49db-dd7c-05d5f264b032"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install -q git+https://github.com/snap-stanford/deepsnap.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZ-o10kvLIpI","executionInfo":{"status":"ok","timestamp":1691818080194,"user_tz":420,"elapsed":41123,"user":{"displayName":"Zeqing Jin","userId":"08270832473685072946"}},"outputId":"83d767a1-ec0c-4971-960b-b4df59c68734"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["2.0.1+cu118\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"rJjQCUgy_omJ","executionInfo":{"status":"ok","timestamp":1691818097312,"user_tz":420,"elapsed":1187,"user":{"displayName":"Zeqing Jin","userId":"08270832473685072946"}}},"outputs":[],"source":["import random\n","import pandas as pd\n","import torch_scatter\n","import torch.nn as nn\n","from torch.nn import Linear, Sequential, LayerNorm, ReLU\n","from torch_geometric.nn.conv import MessagePassing\n","from torch_geometric.data import DataLoader\n","\n","import numpy as np\n","import time\n","import torch.optim as optim\n","from tqdm import trange\n","import pandas as pd\n","import copy\n","import matplotlib.pyplot as plt\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"xBLU45Ci59zA","executionInfo":{"status":"ok","timestamp":1691818097313,"user_tz":420,"elapsed":8,"user":{"displayName":"Zeqing Jin","userId":"08270832473685072946"}}},"outputs":[],"source":["import functools\n","import json\n","from torch_geometric.data import Data\n","import enum\n","import itertools\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fzqln6boBSmY","executionInfo":{"status":"ok","timestamp":1691818113621,"user_tz":420,"elapsed":265,"user":{"displayName":"Zeqing Jin","userId":"08270832473685072946"}}},"outputs":[],"source":["def triangles_to_edges(faces):\n","  # Collect edges from triangles\n","  edges = torch.cat([faces[:, 0:2],\n","                      faces[:, 1:3],\n","                      torch.stack([faces[:, 2], faces[:, 0]], dim=1)], dim=0)\n","  # Those edges are sometimes duplicated (within the mesh) and sometimes\n","  # single (at the mesh boundary).\n","  # Sort & pack edges as single torch.int64\n","  receivers = torch.min(edges, dim=1)[0]\n","  senders = torch.max(edges, dim=1)[0]\n","  packed_edges = torch.stack([senders, receivers], dim=1).to(torch.int64)\n","  # Remove duplicates and unpack\n","  unique_edges = torch.unique(packed_edges, dim=0).to(torch.int32)\n","  senders, receivers = unique_edges[:, 0], unique_edges[:, 1]\n","  # Create two-way connectivity\n","  return torch.cat([senders, receivers], dim=0), torch.cat([receivers, senders], dim=0)\n","\n","from pandas._libs import internals\n","\n","# This class defines the node type you want to classify\n","# For example, internal nodes/surface nodes/nodes under loading/fixed nodes, you can adjust this function based on your problem\n","class NodeType(enum.IntEnum):\n","\n","    internal = 0\n","    upper_lower = 1\n","    SIZE = 2"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":811,"status":"ok","timestamp":1691818118285,"user":{"displayName":"Zeqing Jin","userId":"08270832473685072946"},"user_tz":420},"id":"uCMh9xvV2I6k","outputId":"aabe7c30-8115-4dba-d78e-8055bf13465b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":6}],"source":["data_file=\"/content/drive/MyDrive/hyundai_collaboration/Code_summary/data_preprocessing/sample_data_folder\"\n","\n","file_list=os.listdir(data_file)\n","len(file_list)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":107436,"status":"ok","timestamp":1691819015989,"user":{"displayName":"Zeqing Jin","userId":"08270832473685072946"},"user_tz":420},"id":"ni-HdlkWrK7i","outputId":"63201bf7-636c-4b48-a5ff-2755f5776402"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","[1 1 1 ... 0 0 0]\n","(3361,)\n","2\n","Done collecting data!\n"]}],"source":["def create_dataset(data_file):\n","    data_list=[]\n","    file_name_list=[]\n","    file_list=os.listdir(data_file)\n","    j=1\n","    for item in file_list:\n","\n","        design_name=item.rpartition('_')[0]\n","        print(j)\n","        if design_name not in file_name_list and design_name != \".DS\" :\n","\n","            info=design_name.split(\"_\")\n","            #extra_features=torch.tensor([float(info[-5])*1e-9, float(info[-3])*1e-3, float(info[-1])*np.pi/180])\n","            #extra_features=torch.tensor([float(info[-5])*1e-11, float(info[-3])*1e-5])\n","\n","            file_name_list.append(design_name)\n","\n","            design_node=data_file+'/'+design_name+'_nodes.csv'\n","            design_element=data_file+'/'+design_name+'_elements.csv'\n","\n","            df = pd.read_csv(design_node)\n","            df_node_indices_four=pd.read_csv(design_element)\n","\n","            # four node 3D element to four 3nodel faces\n","\n","            df_node_indices_three = pd.DataFrame( columns = ['elem1','elem2','elem3'])\n","            df_node_indices_three2 = pd.DataFrame( columns = ['elem1','elem2','elem3'])\n","\n","\n","            for i in range(df_node_indices_four.shape[0]):\n","                four_nodes=df_node_indices_four[i:i+1].values.tolist()[0][-4:]\n","\n","                three_nodes=np.array(list(itertools.combinations(four_nodes,3)))\n","                cell_df=pd.DataFrame(three_nodes, columns = ['elem1','elem2','elem3'])\n","                df_node_indices_three = df_node_indices_three.append(cell_df)\n","\n","                three_nodes2=np.array(list(itertools.permutations(four_nodes,3)))\n","                cell_df2=pd.DataFrame(three_nodes2, columns = ['elem1','elem2','elem3'])\n","                df_node_indices_three2 = df_node_indices_three2.append(cell_df2)\n","\n","\n","\n","            cells_index2=np.vstack((df_node_indices_three2[\"elem1\"].to_numpy(),df_node_indices_three2[\"elem2\"].to_numpy(),df_node_indices_three2[\"elem3\"].to_numpy())).T.astype('int32')\n","            cells2=torch.tensor(cells_index2)\n","\n","\n","            # cells (element indices)\n","            cells_index=np.vstack((df_node_indices_three[\"elem1\"].to_numpy(),df_node_indices_three[\"elem2\"].to_numpy(),df_node_indices_three[\"elem3\"].to_numpy())).T.astype('int32')\n","            cells=torch.tensor(cells_index)\n","\n","            # node positions\n","            node_position=np.vstack((df[\"x\"].to_numpy(),df[\"y\"].to_numpy(),df[\"z\"].to_numpy())).T.astype('float32')\n","            mesh_pos=torch.tensor(node_position)\n","\n","            # disp, strain, stress information\n","            stress=torch.tensor(np.vstack((df[\"S11\"].to_numpy(),df[\"S22\"].to_numpy(),df[\"S33\"].to_numpy(),df[\"S12\"].to_numpy(),df[\"S13\"].to_numpy(),df[\"S12.1\"].to_numpy())).T.astype('float32'))\n","            stress_mises=torch.unsqueeze(torch.tensor(df[\"mises\"].to_numpy().T.astype('float32')), 1)\n","            stress11=torch.unsqueeze(torch.tensor(df[\"S11\"].to_numpy().T.astype('float32')), 1)\n","            stress22=torch.unsqueeze(torch.tensor(df[\"S22\"].to_numpy().T.astype('float32')), 1)\n","            stress33=torch.unsqueeze(torch.tensor(df[\"S33\"].to_numpy().T.astype('float32')), 1)\n","            stress12=torch.unsqueeze(torch.tensor(df[\"S12\"].to_numpy().T.astype('float32')), 1)\n","            stress13=torch.unsqueeze(torch.tensor(df[\"S13\"].to_numpy().T.astype('float32')), 1)\n","            stress23=torch.unsqueeze(torch.tensor(df[\"S12.1\"].to_numpy().T.astype('float32')), 1)\n","\n","\n","            # get edge indices\n","            edges = triangles_to_edges(torch.tensor(cells_index))\n","            edge_index = torch.cat( (torch.tensor(edges[0].numpy()).unsqueeze(0) ,\n","                         torch.tensor(edges[1].numpy()).unsqueeze(0)), dim=0).type(torch.long)\n","\n","            # get edge features\n","            u_i=torch.tensor(node_position)[edge_index[0]]\n","            u_j=torch.tensor(node_position)[edge_index[1]]\n","            u_ij=u_i-u_j\n","            u_ij_norm = torch.norm(u_ij,p=2,dim=1,keepdim=True)\n","            edge_attr = torch.cat((u_ij,u_ij_norm),dim=-1).type(torch.float)\n","\n","            # get input x\n","\n","            node_type_info=df[\"nodetype\"].to_numpy().T.astype('int32')\n","            print(node_type_info)\n","            print(node_type_info.shape)\n","            #node_type = torch.tensor(np.array(nn.functional.one_hot(torch.tensor(node_type_info), num_classes=NodeType.SIZE))).squeeze(1)\n","            node_type = nn.functional.one_hot(torch.tensor(node_type_info).to(torch.long), num_classes=NodeType.SIZE)\n","            x_without_features = torch.cat((mesh_pos,node_type),dim=-1).type(torch.float)\n","\n","            #append extra_features to x\n","            #extra_features_stack=extra_features.repeat(x_without_features.shape[0],1)\n","            #x_=torch.cat((mesh_pos,extra_features_stack),dim=-1).type(torch.float)\n","            #x=torch.cat((x_,node_type),dim=-1).type(torch.float)\n","            #x = x_without_features\n","\n","            # get data ist\n","            data_list.append(Data(x=x_without_features, x_without_features=x_without_features ,\n","                                  edge_index=edge_index, edge_attr=edge_attr, stress=stress,\n","                                  cells=cells, cells2=cells2,mesh_pos=mesh_pos, stress11=stress11,\n","                                 stress22=stress22, stress33=stress33, stress12=stress12,\n","                                 stress13=stress13, stress23=stress23,stress_mises=stress_mises, name=design_name ))\n","        else:\n","            pass\n","        j=j+1\n","    print(\"Done collecting data!\")\n","\n","\n","    return torch.save(data_list, os.path.join(\"/content/drive/MyDrive/hyundai_collaboration/Code_summary/data_preprocessing/\" + '3D_data_sample_pytorch.pt'))\n","\n","\n","create_dataset(data_file)"]},{"cell_type":"code","source":["dataset = torch.load(\"/content/drive/MyDrive/hyundai_collaboration/Code_summary/data_preprocessing/3D_data_sample_pytorch.pt\")[0:1]\n","\n","print(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uzLWxYDzObbK","executionInfo":{"status":"ok","timestamp":1691819276857,"user_tz":420,"elapsed":159,"user":{"displayName":"Zeqing Jin","userId":"08270832473685072946"}},"outputId":"eb7be24d-dffd-499a-ff05-8341a98e2090"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["[Data(x=[3361, 5], edge_index=[2, 37590], edge_attr=[37590, 4], x_without_features=[3361, 5], stress=[3361, 6], cells=[52720, 3], cells2=[316320, 3], mesh_pos=[3361, 3], stress11=[3361, 1], stress22=[3361, 1], stress33=[3361, 1], stress12=[3361, 1], stress13=[3361, 1], stress23=[3361, 1], stress_mises=[3361, 1], name='ro_0.226_ri_0.180_w_0.135_sw_0.031_n_4_E_10000000000.0_l_10000.0_rot_0.0')]\n"]}]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":685,"status":"ok","timestamp":1691819278947,"user":{"displayName":"Zeqing Jin","userId":"08270832473685072946"},"user_tz":420},"id":"HQxFILmfAXef","outputId":"815f568a-6c80-43e8-829e-777ee0f7ec27"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Data(x=[3361, 5], edge_index=[2, 37590], edge_attr=[37590, 4], x_without_features=[3361, 5], stress=[3361, 6], cells=[52720, 3], cells2=[316320, 3], mesh_pos=[3361, 3], stress11=[3361, 1], stress22=[3361, 1], stress33=[3361, 1], stress12=[3361, 1], stress13=[3361, 1], stress23=[3361, 1], stress_mises=[3361, 1], name='ro_0.226_ri_0.180_w_0.135_sw_0.031_n_4_E_10000000000.0_l_10000.0_rot_0.0')]\n"]}],"source":["\n","dataset = torch.load(\"/content/drive/MyDrive/hyundai_collaboration/Code_summary/data_preprocessing/3D_data_sample.pt\")[0:1]\n","\n","print(dataset)"]},{"cell_type":"markdown","source":["#### * a meshed wheel structure with n nodes has a nodal input size of n×5 (see \"x\") for the “Original Dataset” without augmented features such as loading force or rotation angle information (e.g. row_i:[x_i,y_i,z_i ]+[node type])"],"metadata":{"id":"cUePl3-xzXbO"}},{"cell_type":"markdown","source":["#### * An edge input has a size of m×4 (see \"edge_attr\") for a meshed wheel structure with m edges across all the dataset. The output size is always the same with a size of n×6 (see \"stress\") for stresses prediction."],"metadata":{"id":"NY57t8ryzytH"}},{"cell_type":"markdown","source":["#### *  Now, the .pt file will be our processed dataset to be used for traning and testing.\n","\n","\n"],"metadata":{"id":"wVXYKtwn0LN1"}}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}